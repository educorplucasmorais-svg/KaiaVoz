# ğŸ¤ Arquitetura de IA de Voz - Kaia

Este documento descreve a arquitetura de reconhecimento de voz (ASR) e sÃ­ntese de voz (TTS) do assistente Kaia, incluindo configuraÃ§Ãµes otimizadas para baixa latÃªncia e alta precisÃ£o.

## ğŸ“‹ Ãndice

1. [VisÃ£o Geral da Arquitetura](#visÃ£o-geral-da-arquitetura)
2. [MÃ³dulo de Captura de Ãudio (VAD/I/O)](#mÃ³dulo-de-captura-de-Ã¡udio-vadio)
3. [Reconhecimento de Fala (ASR)](#reconhecimento-de-fala-asr)
4. [SÃ­ntese de Voz (TTS)](#sÃ­ntese-de-voz-tts)
5. [OtimizaÃ§Ã£o de LatÃªncia](#otimizaÃ§Ã£o-de-latÃªncia)
6. [SeguranÃ§a](#seguranÃ§a)
7. [PrÃ³ximos Passos](#prÃ³ximos-passos)

---

## VisÃ£o Geral da Arquitetura

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    FRONTEND (React/Browser)                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  useSpeech Hook                                            â”‚ â”‚
â”‚  â”‚  â”œâ”€ Web Speech API (SpeechRecognition)                     â”‚ â”‚
â”‚  â”‚  â”œâ”€ VAD (Voice Activity Detection) integrado               â”‚ â”‚
â”‚  â”‚  â”œâ”€ Error Recovery com retry automÃ¡tico                    â”‚ â”‚
â”‚  â”‚  â””â”€ Confidence scoring                                     â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  useTTS Hook                                               â”‚ â”‚
â”‚  â”‚  â”œâ”€ ElevenLabs (premium, cloud)                            â”‚ â”‚
â”‚  â”‚  â”œâ”€ Edge TTS (Microsoft, cloud)                            â”‚ â”‚
â”‚  â”‚  â””â”€ Web Speech API (browser, local)                        â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â†“ POST /api/ai/voice â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  BACKEND (Express/Node.js)                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  NeuralCoreAgent                                           â”‚ â”‚
â”‚  â”‚  â”œâ”€ ValidaÃ§Ã£o de seguranÃ§a (bloqueio de comandos perigosos)â”‚ â”‚
â”‚  â”‚  â”œâ”€ AnÃ¡lise de intenÃ§Ã£o (6 tipos)                          â”‚ â”‚
â”‚  â”‚  â”œâ”€ Abbacus LLM (opcional, para respostas inteligentes)    â”‚ â”‚
â”‚  â”‚  â””â”€ Pattern matching local (fallback)                      â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## MÃ³dulo de Captura de Ãudio (VAD/I/O)

### ConfiguraÃ§Ã£o do VAD (Voice Activity Detection)

O VAD Ã© crÃ­tico para determinar quando o usuÃ¡rio comeÃ§a e para de falar. A implementaÃ§Ã£o atual usa a Web Speech API com configuraÃ§Ãµes otimizadas:

```typescript
// apps/frontend/src/hooks/useSpeech.ts
const config = {
  silenceTimeout: 1500,  // 1.5s de silÃªncio = fim da fala
  maxDuration: 30000,    // 30s mÃ¡ximo de gravaÃ§Ã£o
  autoRestart: true,     // Reiniciar automaticamente apÃ³s silÃªncio
  maxRetries: 3          // Tentativas em caso de erro
}
```

### ParÃ¢metros de ConfiguraÃ§Ã£o

| ParÃ¢metro | Valor PadrÃ£o | DescriÃ§Ã£o |
|-----------|--------------|-----------|
| `silenceTimeout` | 1500ms | Tempo de silÃªncio antes de finalizar a fala |
| `maxDuration` | 30000ms | DuraÃ§Ã£o mÃ¡xima de uma gravaÃ§Ã£o |
| `autoRestart` | true | Reiniciar reconhecimento automaticamente |
| `maxRetries` | 3 | NÃºmero de tentativas em erros recuperÃ¡veis |

### Tratamento de Erros

A implementaÃ§Ã£o trata os seguintes tipos de erros:

| CÃ³digo | DescriÃ§Ã£o | RecuperÃ¡vel |
|--------|-----------|-------------|
| `no-speech` | Nenhuma fala detectada | âœ… Sim |
| `audio-capture` | Erro de captura de Ã¡udio | âœ… Sim |
| `not-allowed` | PermissÃ£o negada | âŒ NÃ£o |
| `network` | Erro de rede | âœ… Sim |
| `aborted` | Reconhecimento cancelado | âœ… Sim |
| `language-not-supported` | Idioma nÃ£o suportado | âŒ NÃ£o |
| `service-not-allowed` | ServiÃ§o nÃ£o disponÃ­vel | âŒ NÃ£o |

---

## Reconhecimento de Fala (ASR)

### ImplementaÃ§Ã£o Atual: Web Speech API

**Vantagens:**
- âœ… Funciona nativamente no navegador
- âœ… Sem custo adicional
- âœ… Suporte a portuguÃªs brasileiro (pt-BR)
- âœ… Resultados em tempo real (interim results)

**LimitaÃ§Ãµes:**
- âŒ Requer conexÃ£o com internet (usa servidores Google/Microsoft)
- âŒ PrecisÃ£o variÃ¡vel dependendo do navegador
- âŒ NÃ£o funciona em todos os navegadores (Firefox tem suporte limitado)

### RecomendaÃ§Ãµes para Melhoria (Futuro)

Para aplicaÃ§Ãµes de produÃ§Ã£o com requisitos de baixa latÃªncia, considere:

#### 1. Faster-Whisper (Recomendado para pt-BR)

```python
# Exemplo de integraÃ§Ã£o futura
from faster_whisper import WhisperModel

model = WhisperModel("large-v3", device="cuda", compute_type="float16")
segments, info = model.transcribe("audio.mp3", language="pt")
```

**MÃ©tricas esperadas:**
- LatÃªncia: 350-500ms para frases curtas
- WER (Word Error Rate): ~5-8% para pt-BR
- Requer GPU com CUDA

#### 2. Silero VAD (DetecÃ§Ã£o de Atividade de Voz)

```python
# Exemplo de integraÃ§Ã£o futura
import torch
model, utils = torch.hub.load(repo_or_dir='snakers4/silero-vad', model='silero_vad')
get_speech_timestamps = utils[0]

# Processa chunk de Ã¡udio em < 1ms
speech_timestamps = get_speech_timestamps(audio, model)
```

**BenefÃ­cios:**
- Processamento em < 1ms por chunk
- Detecta inÃ­cio e fim de fala com precisÃ£o
- Funciona offline

---

## SÃ­ntese de Voz (TTS)

### Provedores DisponÃ­veis

1. **ElevenLabs** (Premium)
   - Qualidade: â­â­â­â­â­
   - LatÃªncia: ~200-400ms
   - Custo: Pago por caractere
   - ConfiguraÃ§Ã£o: `ELEVENLABS_API_KEY`

2. **Edge TTS** (Microsoft)
   - Qualidade: â­â­â­â­
   - LatÃªncia: ~150-300ms
   - Custo: Gratuito
   - Vozes: `pt-BR-AntonioNeural`, `pt-BR-FranciscaNeural`

3. **Web Speech API** (Browser)
   - Qualidade: â­â­â­
   - LatÃªncia: ~50-100ms
   - Custo: Gratuito
   - Depende das vozes instaladas no sistema

### ConfiguraÃ§Ã£o de TTS

```env
# apps/server/.env
ELEVENLABS_API_KEY=sk_xxxxx
ELEVENLABS_VOICE_ID=21m00Tcm4TlvDq8ikWAM
ELEVENLABS_MODEL_ID=eleven_multilingual_v2
```

---

## OtimizaÃ§Ã£o de LatÃªncia

### Metas de LatÃªncia

Para uma conversa fluida, a latÃªncia total deve ser < 600ms:

| Componente | Meta | Atual |
|------------|------|-------|
| VAD (detecÃ§Ã£o de fim de fala) | < 1ms | ~1ms âœ… |
| ASR (transcriÃ§Ã£o) | 350-500ms | ~300-500ms âœ… |
| LLM (TTFT) | 100-300ms | ~200-400ms âš ï¸ |
| TTS (primeira sÃ­laba audÃ­vel) | 100-250ms | ~150-300ms âœ… |

### EstratÃ©gias de OtimizaÃ§Ã£o

#### 1. Streaming de Resposta

Implemente streaming dual para reduzir latÃªncia percebida:

```typescript
// Enviar tokens do LLM para TTS assim que gerados
async function* streamResponse(text: string) {
  const chunks = splitIntoSentences(text);
  for (const chunk of chunks) {
    yield chunk;
    // TTS comeÃ§a a falar enquanto LLM ainda gera
    await speakChunk(chunk);
  }
}
```

#### 2. Cache Inteligente

```typescript
// apps/server/src/services/ai.ts
const responseCache = new Map<string, { response: string; timestamp: number }>()
const CACHE_TTL = 5 * 60 * 1000 // 5 minutos
```

#### 3. Prompt Engineering para ConcisÃ£o

```
Responda de forma concisa em 1-3 frases.
MÃ¡ximo 50 palavras.
```

---

## SeguranÃ§a

### ValidaÃ§Ã£o de Comandos

O NeuralCoreAgent implementa validaÃ§Ã£o de seguranÃ§a para bloquear comandos perigosos:

```typescript
// apps/server/src/services/neuralcore.ts
const blockedPatterns = [
  /system32/i,
  /delete.*windows/i,
  /rm\s+-rf\s+\//i,
  /format\s+c:/i,
  /shutdown/i
]
```

### OperaÃ§Ãµes Permitidas

```typescript
const allowedOperations = [
  'open_file',
  'search_file',
  'create_reminder',
  'get_time',
  'get_weather',
  'play_music',
  'volume_control'
]
```

### RecomendaÃ§Ãµes de SeguranÃ§a

1. **Sandboxing (Docker)**
   ```yaml
   # docker-compose.yml
   services:
     kaia-agent:
       image: kaia/agent
       security_opt:
         - no-new-privileges:true
       read_only: true
       tmpfs:
         - /tmp
   ```

2. **PrincÃ­pio do MÃ­nimo PrivilÃ©gio (POLP)**
   - O agente nunca deve ter acesso direto ao shell
   - Use ferramentas (tools) tipadas com validaÃ§Ã£o de argumentos
   - Confirme aÃ§Ãµes destrutivas com o usuÃ¡rio

3. **Ferramentas Proxy (FaÃ§ade Pattern)**
   ```typescript
   // Nunca execute comandos diretos
   // Use funÃ§Ãµes proxy de alto nÃ­vel
   const tools = {
     open_file: async (path: string) => {
       // Validar path antes de executar
       if (isPathSafe(path)) {
         return executeCommand(`start ${path}`)
       }
       throw new Error('Path nÃ£o permitido')
     }
   }
   ```

---

## PrÃ³ximos Passos

### Curto Prazo (1-2 semanas)

- [ ] Implementar Silero VAD para detecÃ§Ã£o de fim de fala mais precisa
- [ ] Adicionar mÃ©tricas de latÃªncia no frontend
- [ ] Melhorar feedback visual durante processamento

### MÃ©dio Prazo (1-2 meses)

- [ ] Integrar Faster-Whisper para ASR local com GPU
- [ ] Implementar streaming de resposta TTS
- [ ] Adicionar suporte a wake word ("Oi Kaia")

### Longo Prazo (3-6 meses)

- [ ] Treinar modelo TTS customizado para pt-BR
- [ ] Implementar Voice Cloning para personalizaÃ§Ã£o
- [ ] Adicionar suporte a mÃºltiplos idiomas

---

## ReferÃªncias

- [Web Speech API MDN](https://developer.mozilla.org/en-US/docs/Web/API/Web_Speech_API)
- [Faster-Whisper GitHub](https://github.com/guillaumekln/faster-whisper)
- [Silero VAD GitHub](https://github.com/snakers4/silero-vad)
- [ElevenLabs API](https://elevenlabs.io/docs)
- [LangChain Documentation](https://js.langchain.com/docs/)

---

**Ãšltima atualizaÃ§Ã£o:** 16/12/2025
**VersÃ£o:** 1.1.0
